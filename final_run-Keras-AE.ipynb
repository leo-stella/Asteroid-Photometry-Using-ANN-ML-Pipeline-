{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from astropy.io import fits\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# intel HD does not support CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical approach to compare with ANN\n",
    "def rolo_b_me(alpha, emission, incidence):\n",
    "    '''\n",
    "    Here we obtain the reflectance for any photometric angle (using degrees as input)  \n",
    "    according to our classic photometric modeling. This model consists of the Sommel-Seeliger \n",
    "    disk function and ROLO as a phase function.\n",
    "\n",
    "    Use example: for phase=30ยบ, emission=0ยบ and incidence=30ยบ - ipwg(30, 0, 30)\n",
    "    \n",
    "    Inputs: phase, emission and incidence angles\n",
    "    Output: reflectance\n",
    "    '''\n",
    "    # parameters\n",
    "    C_0, C_1, A_0, A_1, A_2, A_3, A_4=np.loadtxt('parameters.txt')  \n",
    "    \n",
    "    # converting degrees to radians:\n",
    "    emission=np.deg2rad(emission)    \n",
    "    incidence=np.deg2rad(incidence)\n",
    "    \n",
    "    # computing reflectance according to this photometric model:\n",
    "    disk = (np.cos(incidence)/(np.cos(incidence)+np.cos(emission)))\n",
    "    phase = C_0*np.exp(-C_1*alpha) + A_0 + A_1*alpha + A_2*(alpha)**2 + A_3*(alpha)**3  + A_4*(alpha)**4 \n",
    "    \n",
    "    reflectance = disk * phase\n",
    "    \n",
    "    return reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(ID):\n",
    "    '''\n",
    "     Here we extract features and labels using the ID of each image.\n",
    "    Later we convert these data in the apropiate format for training or validation.\n",
    "    It calls to data_normalization() function.\n",
    "    '''\n",
    "    \n",
    "    iof_n, phase_n, emission_n, incidence_n = data_normalization(ID)\n",
    "    \n",
    "    \n",
    "    # packing data\n",
    "    features = np.zeros((len(phase_n),3)) \n",
    "    features[:,0] = phase_n\n",
    "    features[:,1] = emission_n\n",
    "    features[:,2] = incidence_n\n",
    "    \n",
    "    features = torch.FloatTensor(features)\n",
    "    features = features.to(device)\n",
    "    \n",
    "    labels = np.zeros((len(iof_n),1))\n",
    "    labels[:,0] = iof_n\n",
    "    \n",
    "    labels = torch.FloatTensor(labels)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(ID):\n",
    "    '''\n",
    "    In this function we rescale data between 0 and 1, a very important step before trainning a neural network.\n",
    "    It calls to loading_and_cleaning_data() function.\n",
    "    '''\n",
    "    iof_, phase_, emission_, incidence_ = loading_and_cleaning_data(ID)\n",
    "       \n",
    "    #normalizing data\n",
    "    iof_n=iof_/0.06; phase_n=phase_/90; emission_n=emission_/82; incidence_n=incidence_/82\n",
    "\n",
    "    return iof_n, phase_n, emission_n, incidence_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_and_cleaning_data(ID):\n",
    "    '''\n",
    "    This function is for loading iof, phase, emission, incidence values for each image. \n",
    "    '''\n",
    "    #criterion for removing data:\n",
    "    em, eM = (0, 82)        # emission limits  \n",
    "    im, iM = (0, 82)          # incidence limits\n",
    "    pm, pM = (0, 90)       # phase limits\n",
    "    rm, rM =  (0.001,1)  # reflectance higher limits\n",
    "    \n",
    "    fits_file = fits.getdata(ID, ignore_missing_end=True)\n",
    "    \n",
    "    iof = fits_file[0]\n",
    "    phase = fits_file[1]\n",
    "    emission = fits_file[2]\n",
    "    incidence = fits_file[3]\n",
    "    \n",
    "    idxsort = (emission >= em) & (emission <= eM) & \\\n",
    "              (incidence >= im) & (incidence <= iM) & \\\n",
    "              (phase >= pm) & (phase <= pM) & \\\n",
    "              (iof >= rm) & (iof <= rM) \n",
    "    \n",
    "    return iof[idxsort], phase[idxsort], emission[idxsort], incidence[idxsort] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ID list of files:\n",
    "files_ID=[]\n",
    "for i in sorted(glob.glob('reduced_phocubes/*reduce.fits')):\n",
    "    files_ID.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "951"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# defining global tensors \n",
    "\n",
    "final_training_features = torch.zeros(0)\n",
    "final_training_labels = torch.zeros(0)\n",
    "final_validation_features = torch.zeros(0)\n",
    "final_validation_labels = torch.zeros(0)\n",
    "\n",
    "final_training_features = final_training_features.to(device)\n",
    "final_training_labels = final_training_labels.to(device)\n",
    "final_validation_features = final_validation_features.to(device)\n",
    "final_validation_labels = final_validation_labels.to(device)\n",
    "\n",
    "for file in files_ID:\n",
    "    \n",
    "    # loading training data from files_ID list\n",
    "    _features, _labels = data_preparation(file)\n",
    "    if len(_features) != 0:\n",
    "        np.random.seed(10)\n",
    "        # Selecting 1000 random values of this image\n",
    "        try:\n",
    "            mask_temp = np.random.choice(len(_features),1000,replace=False)\n",
    "        \n",
    "        except:\n",
    "            mask_temp = np.random.choice(len(_features),len(_features),replace=False)\n",
    "        \n",
    "        split = int(len(mask_temp)*(9/10))\n",
    "        mask_train = mask_temp[0:split]\n",
    "        mask_val = mask_temp[split:]\n",
    "        \n",
    "        training_features =  _features[mask_train]\n",
    "        final_training_features = torch.cat([final_training_features,training_features])\n",
    "        \n",
    "        training_labels = _labels[mask_train]\n",
    "        final_training_labels = torch.cat([final_training_labels,training_labels])\n",
    "\n",
    "        # Selecting 10% random values of this image\n",
    "        \n",
    "        validation_features =  _features[mask_val]\n",
    "        final_validation_features=torch.cat([final_validation_features,validation_features])\n",
    "\n",
    "        validation_labels = _labels[mask_val]\n",
    "        final_validation_labels=torch.cat([final_validation_labels,validation_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0044)\n"
     ]
    }
   ],
   "source": [
    "#ROLO eficciency using MSE:\n",
    "phase=final_validation_features.cpu().numpy()[:,0]*90\n",
    "emission=final_validation_features.cpu().numpy()[:,1]*82\n",
    "incidence=final_validation_features.cpu().numpy()[:,2]*82\n",
    "prediction_ROLO=torch.tensor(rolo_b_me(phase, emission, incidence)/0.06).to(device)\n",
    "eff_ROLO=torch.mean((prediction_ROLO-final_validation_labels.t())**2)\n",
    "print(eff_ROLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417025 46480\n"
     ]
    }
   ],
   "source": [
    "print(len(final_training_features), len(final_validation_features))\n",
    "final_training_features = final_training_features.numpy()\n",
    "final_validation_features = final_validation_features.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "418/418 [==============================] - 4s 6ms/step - loss: 0.0088 - accuracy: 0.8435 - val_loss: 2.6698e-04 - val_accuracy: 0.9718\n",
      "Epoch 2/20\n",
      "418/418 [==============================] - 2s 6ms/step - loss: 1.5683e-04 - accuracy: 0.9758 - val_loss: 1.0369e-04 - val_accuracy: 0.9826\n",
      "Epoch 3/20\n",
      "418/418 [==============================] - 2s 6ms/step - loss: 6.4331e-05 - accuracy: 0.9816 - val_loss: 5.0152e-05 - val_accuracy: 0.9750\n",
      "Epoch 4/20\n",
      "418/418 [==============================] - 3s 7ms/step - loss: 4.3965e-05 - accuracy: 0.9809 - val_loss: 3.7072e-05 - val_accuracy: 0.9818\n",
      "Epoch 5/20\n",
      "418/418 [==============================] - 3s 7ms/step - loss: 3.5506e-05 - accuracy: 0.9818 - val_loss: 3.0966e-05 - val_accuracy: 0.9823\n",
      "Epoch 6/20\n",
      "418/418 [==============================] - 4s 10ms/step - loss: 3.0876e-05 - accuracy: 0.9813 - val_loss: 4.5476e-05 - val_accuracy: 0.9540\n",
      "Epoch 7/20\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 2.7086e-05 - accuracy: 0.9820 - val_loss: 2.4795e-05 - val_accuracy: 0.9721\n",
      "Epoch 8/20\n",
      "418/418 [==============================] - 7s 16ms/step - loss: 2.4156e-05 - accuracy: 0.9819 - val_loss: 3.2460e-05 - val_accuracy: 0.9644\n",
      "Epoch 9/20\n",
      "418/418 [==============================] - 6s 14ms/step - loss: 2.2800e-05 - accuracy: 0.9823 - val_loss: 2.8925e-05 - val_accuracy: 0.9833\n",
      "Epoch 10/20\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 2.1233e-05 - accuracy: 0.9817 - val_loss: 1.8058e-05 - val_accuracy: 0.9866\n",
      "Epoch 11/20\n",
      "418/418 [==============================] - 6s 13ms/step - loss: 2.0277e-05 - accuracy: 0.9826 - val_loss: 1.9904e-05 - val_accuracy: 0.9861\n",
      "Epoch 12/20\n",
      "418/418 [==============================] - 6s 14ms/step - loss: 1.9539e-05 - accuracy: 0.9827 - val_loss: 1.3442e-05 - val_accuracy: 0.9872\n",
      "Epoch 13/20\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1.7836e-05 - accuracy: 0.9836 - val_loss: 1.4892e-05 - val_accuracy: 0.9869\n",
      "Epoch 14/20\n",
      "418/418 [==============================] - 5s 12ms/step - loss: 1.7560e-05 - accuracy: 0.9833 - val_loss: 2.2834e-05 - val_accuracy: 0.9838\n",
      "Epoch 15/20\n",
      "418/418 [==============================] - 3s 7ms/step - loss: 1.6678e-05 - accuracy: 0.9832 - val_loss: 1.4526e-05 - val_accuracy: 0.9861\n",
      "Epoch 16/20\n",
      "418/418 [==============================] - 3s 7ms/step - loss: 1.7107e-05 - accuracy: 0.9836 - val_loss: 1.9014e-05 - val_accuracy: 0.9810\n",
      "Epoch 17/20\n",
      "418/418 [==============================] - 3s 8ms/step - loss: 1.5739e-05 - accuracy: 0.9837 - val_loss: 1.2323e-05 - val_accuracy: 0.9874\n",
      "Epoch 18/20\n",
      "418/418 [==============================] - 3s 7ms/step - loss: 1.5512e-05 - accuracy: 0.9836 - val_loss: 2.6741e-05 - val_accuracy: 0.9656\n",
      "Epoch 19/20\n",
      "418/418 [==============================] - 2s 5ms/step - loss: 1.5044e-05 - accuracy: 0.9841 - val_loss: 2.5783e-05 - val_accuracy: 0.9847\n",
      "Epoch 20/20\n",
      "418/418 [==============================] - 3s 7ms/step - loss: 1.5240e-05 - accuracy: 0.9837 - val_loss: 1.9815e-05 - val_accuracy: 0.9803\n",
      "Model: \"autoencoder_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_3 (Sequential)   (None, 9)                 5001      \n",
      "                                                                 \n",
      " sequential_4 (Sequential)   (None, 3)                 4995      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,996\n",
      "Trainable params: 9,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, precision_score ,recall_score\n",
    "from tensorflow.keras import layers,losses\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self,latent_dim=9):\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.latent_dim=9\n",
    "        self.encoder=tf.keras.Sequential([\n",
    "            layers.Dense(64,activation=\"relu\"),\n",
    "            layers.Dense(64,activation=\"relu\"),\n",
    "            layers.Dense(latent_dim,activation=\"relu\")])\n",
    "        \n",
    "        self.decoder=tf.keras.Sequential([\n",
    "            layers.Dense(64,activation=\"relu\"),\n",
    "            layers.Dense(64,activation=\"relu\"),\n",
    "            layers.Dense(3,activation=\"sigmoid\")])\n",
    "        \n",
    "    def call(self,x):\n",
    "        encoded=self.encoder(x)\n",
    "        decoded=self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder=Autoencoder()\n",
    "autoencoder.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "autoencoder.fit(final_training_features,final_training_features, \n",
    "                validation_data=(final_validation_features, final_validation_features), epochs=20, batch_size=1000)\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417025, 9)\n",
      "(46480, 9)\n",
      "(417025, 12)\n",
      "(46480, 12)\n"
     ]
    }
   ],
   "source": [
    "x_training_encoded = autoencoder.encoder(final_training_features).numpy()\n",
    "x_vaidation_encoded = autoencoder.encoder(final_validation_features).numpy()\n",
    "\n",
    "print(x_training_encoded.shape)\n",
    "print(x_vaidation_encoded.shape)\n",
    "\n",
    "import numpy as np\n",
    "x_training_concat = np.concatenate((final_training_features, x_training_encoded), axis = 1)\n",
    "x_validation_concat = np.concatenate((final_validation_features, x_vaidation_encoded), axis = 1)\n",
    "\n",
    "print(x_training_concat.shape)\n",
    "print(x_validation_concat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def correlated_features(data,threshold):\n",
    "    corr_col=set()\n",
    "    confusion=data.corr()\n",
    "    for i in range(confusion.shape[0]):\n",
    "        for j in range(i): \n",
    "             if confusion.iloc[i,j]>threshold:\n",
    "                    corr_col.add(confusion.columns[i])\n",
    "    return corr_col\n",
    "\n",
    "pd_x_training_concat = pd.DataFrame (x_training_concat)\n",
    "pd_x_validation_concat = pd.DataFrame (x_validation_concat)\n",
    "\n",
    "corr_features= correlated_features(pd_x_training_concat , 0.9)\n",
    "print(len(corr_features))\n",
    "\n",
    "x_training_corr = pd_x_training_concat.drop(corr_features,axis=1)\n",
    "x_validation_corr = pd_x_validation_concat.drop(corr_features,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA()\n",
    "pca.fit(x_training_corr)\n",
    "plt.figure()\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Explained Variance')  \n",
    "plt.title('Explained Variance per Principal Components ')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(417025, 3)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=3)\n",
    "x_training_pca = pca.fit_transform(x_training_corr)\n",
    "x_validation_pca = pca.fit_transform(x_validation_corr)\n",
    "print(x_training_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "finall_training_features = tf.convert_to_tensor(x_training_pca)\n",
    "finall_validation_features = tf.convert_to_tensor(x_validation_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_size = 3\n",
    "finall_training_labels = tf.convert_to_tensor(final_training_labels)\n",
    "finall_validation_labels =  tf.convert_to_tensor(final_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up and defining a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2086/2086 [==============================] - 11s 5ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 2/20\n",
      "2086/2086 [==============================] - 11s 5ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 3/20\n",
      "2086/2086 [==============================] - 13s 6ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "2086/2086 [==============================] - 9s 4ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 5/20\n",
      "2086/2086 [==============================] - 7s 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 6/20\n",
      "2086/2086 [==============================] - 8s 4ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 7/20\n",
      "2086/2086 [==============================] - 9s 4ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 8/20\n",
      "2086/2086 [==============================] - 7s 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/20\n",
      "2086/2086 [==============================] - 6s 3ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 10/20\n",
      "2086/2086 [==============================] - 6s 3ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 11/20\n",
      "2086/2086 [==============================] - 12s 6ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 12/20\n",
      "2086/2086 [==============================] - 11s 5ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 13/20\n",
      "2086/2086 [==============================] - 8s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 14/20\n",
      "2086/2086 [==============================] - 9s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 15/20\n",
      "2086/2086 [==============================] - 12s 6ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 16/20\n",
      "2086/2086 [==============================] - 13s 6ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 17/20\n",
      "2086/2086 [==============================] - 14s 7ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 18/20\n",
      "2086/2086 [==============================] - 9s 4ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 19/20\n",
      "2086/2086 [==============================] - 6s 3ms/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 20/20\n",
      "2086/2086 [==============================] - 7s 3ms/step - loss: 0.0035 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_shape=(input_size,), activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "modelfit = model.fit(finall_training_features, finall_training_labels, \n",
    "                     validation_data=(finall_validation_features, finall_validation_labels), epochs=20, batch_size=200)\n",
    "\n",
    "best_loss = modelfit.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0044)\n",
      "0.003584346268326044\n"
     ]
    }
   ],
   "source": [
    "print(eff_ROLO)\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.5595)\n"
     ]
    }
   ],
   "source": [
    "print((eff_ROLO - best_loss)*100/eff_ROLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
