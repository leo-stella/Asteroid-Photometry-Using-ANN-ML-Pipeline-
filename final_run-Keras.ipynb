{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from astropy.io import fits\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if (torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "# intel HD does not support CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical approach to compare with ANN\n",
    "def rolo_b_me(alpha, emission, incidence):\n",
    "    '''\n",
    "    Here we obtain the reflectance for any photometric angle (using degrees as input)  \n",
    "    according to our classic photometric modeling. This model consists of the Sommel-Seeliger \n",
    "    disk function and ROLO as a phase function.\n",
    "\n",
    "    Use example: for phase=30ยบ, emission=0ยบ and incidence=30ยบ - ipwg(30, 0, 30)\n",
    "    \n",
    "    Inputs: phase, emission and incidence angles\n",
    "    Output: reflectance\n",
    "    '''\n",
    "    # parameters\n",
    "    C_0, C_1, A_0, A_1, A_2, A_3, A_4=np.loadtxt('parameters.txt')  \n",
    "    print(len(alpha))\n",
    "    # converting degrees to radians:\n",
    "    emission=np.deg2rad(emission)    \n",
    "    incidence=np.deg2rad(incidence)\n",
    "    \n",
    "    # computing reflectance according to this photometric model:\n",
    "    disk = (np.cos(incidence)/(np.cos(incidence)+np.cos(emission)))\n",
    "    phase = C_0*np.exp(-C_1*alpha) + A_0 + A_1*alpha + A_2*(alpha)**2 + A_3*(alpha)**3  + A_4*(alpha)**4 \n",
    "    \n",
    "    reflectance = disk * phase\n",
    "    \n",
    "    return reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(ID):\n",
    "    '''\n",
    "     Here we extract features and labels using the ID of each image.\n",
    "    Later we convert these data in the apropiate format for training or validation.\n",
    "    It calls to data_normalization() function.\n",
    "    '''\n",
    "    \n",
    "    iof_n, phase_n, emission_n, incidence_n = data_normalization(ID)\n",
    "    \n",
    "    \n",
    "    # packing data\n",
    "    features = np.zeros((len(phase_n),3)) \n",
    "    features[:,0] = phase_n\n",
    "    features[:,1] = emission_n\n",
    "    features[:,2] = incidence_n\n",
    "    \n",
    "    features = torch.FloatTensor(features)\n",
    "    features = features.to(device)\n",
    "    \n",
    "    labels = np.zeros((len(iof_n),1))\n",
    "    labels[:,0] = iof_n\n",
    "    \n",
    "    labels = torch.FloatTensor(labels)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_normalization(ID):\n",
    "    '''\n",
    "   In this function we rescale data between 0 and 1, a very important step before trainning a neural network.\n",
    "    It calls to loading_and_cleaning_data() function.\n",
    "    '''\n",
    "    iof_, phase_, emission_, incidence_ = loading_and_cleaning_data(ID)\n",
    "       \n",
    "    #normalizing data\n",
    "    iof_n=iof_/0.06; phase_n=phase_/90; emission_n=emission_/82; incidence_n=incidence_/82\n",
    "\n",
    "    return iof_n, phase_n, emission_n, incidence_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loading_and_cleaning_data(ID):\n",
    "    '''\n",
    "    This function is for loading iof, phase, emission, incidence values for each image. \n",
    "    '''\n",
    "    #criterion for removing data:\n",
    "    em, eM = (0, 82)        # emission limits  \n",
    "    im, iM = (0, 82)          # incidence limits\n",
    "    pm, pM = (0, 90)       # phase limits\n",
    "    rm, rM =  (0.001,1)  # reflectance higher limits\n",
    "    \n",
    "    fits_file = fits.getdata(ID, ignore_missing_end=True)\n",
    "    \n",
    "    iof = fits_file[0]\n",
    "    phase = fits_file[1]\n",
    "    emission = fits_file[2]\n",
    "    incidence = fits_file[3]\n",
    "    \n",
    "    idxsort = (emission >= em) & (emission <= eM) & \\\n",
    "              (incidence >= im) & (incidence <= iM) & \\\n",
    "              (phase >= pm) & (phase <= pM) & \\\n",
    "              (iof >= rm) & (iof <= rM) \n",
    "    \n",
    "    return iof[idxsort], phase[idxsort], emission[idxsort], incidence[idxsort] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ID list of files:\n",
    "files_ID=[]\n",
    "for i in sorted(glob.glob('reduced_phocubes/*reduce.fits')):\n",
    "    files_ID.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "951"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# defining global tensors \n",
    "\n",
    "final_training_features = torch.zeros(0)\n",
    "final_training_labels = torch.zeros(0)\n",
    "final_validation_features = torch.zeros(0)\n",
    "final_validation_labels = torch.zeros(0)\n",
    "\n",
    "final_training_features = final_training_features.to(device)\n",
    "final_training_labels = final_training_labels.to(device)\n",
    "final_validation_features = final_validation_features.to(device)\n",
    "final_validation_labels = final_validation_labels.to(device)\n",
    "\n",
    "for file in files_ID:\n",
    "    \n",
    "    # loading training data from files_ID list\n",
    "    _features, _labels = data_preparation(file)\n",
    "    if len(_features) != 0:\n",
    "        np.random.seed(10)\n",
    "        # Selecting 1000 random values of this image\n",
    "        try:\n",
    "            mask_temp = np.random.choice(len(_features),1000,replace=False)\n",
    "        \n",
    "        except:\n",
    "            mask_temp = np.random.choice(len(_features),len(_features),replace=False)\n",
    "        \n",
    "        split = int(len(mask_temp)*(9/10))\n",
    "        mask_train = mask_temp[0:split]\n",
    "        mask_val = mask_temp[split:]\n",
    "        \n",
    "        training_features =  _features[mask_train]\n",
    "        final_training_features = torch.cat([final_training_features,training_features])\n",
    "        \n",
    "        training_labels = _labels[mask_train]\n",
    "        final_training_labels = torch.cat([final_training_labels,training_labels])\n",
    "        \n",
    "        validation_features =  _features[mask_val]\n",
    "        final_validation_features=torch.cat([final_validation_features,validation_features])\n",
    "\n",
    "        validation_labels = _labels[mask_val]\n",
    "        final_validation_labels=torch.cat([final_validation_labels,validation_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46480\n",
      "tensor(0.0044)\n"
     ]
    }
   ],
   "source": [
    "#ROLO eficciency using MSE:\n",
    "start_time = time.time()\n",
    "phase=final_validation_features.cpu().numpy()[:,0]*90\n",
    "emission=final_validation_features.cpu().numpy()[:,1]*82\n",
    "incidence=final_validation_features.cpu().numpy()[:,2]*82\n",
    "prediction_ROLO=torch.tensor(rolo_b_me(phase, emission, incidence)/0.06).to(device)\n",
    "eff_ROLO=torch.mean((prediction_ROLO-final_validation_labels.t())**2)\n",
    "print(eff_ROLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417025 46480\n"
     ]
    }
   ],
   "source": [
    "print(len(final_training_features), len(final_validation_features))\n",
    "final_training_features = final_training_features.numpy()\n",
    "final_validation_features = final_validation_features.numpy()\n",
    "final_training_labels = final_training_labels.numpy()\n",
    "final_validation_labels = final_validation_labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "input_size = 3\n",
    "final_training_labels = tf.convert_to_tensor(final_training_labels)\n",
    "final_validation_lables =  tf.convert_to_tensor(final_validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up and defining a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2086/2086 [==============================] - 5s 2ms/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 2/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 3/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 4/20\n",
      "2086/2086 [==============================] - 5s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 5/20\n",
      "2086/2086 [==============================] - 17s 8ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 6/20\n",
      "2086/2086 [==============================] - 8s 4ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 7/20\n",
      "2086/2086 [==============================] - 5s 3ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 8/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 10/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 11/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 12/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 13/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 14/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 15/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 16/20\n",
      "2086/2086 [==============================] - 4s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 17/20\n",
      "2086/2086 [==============================] - 6s 3ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 18/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 19/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 20/20\n",
      "2086/2086 [==============================] - 3s 2ms/step - loss: 0.0036 - val_loss: 0.0036\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "numpy.random.seed(7)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(15, input_shape=(input_size,), activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "modelfit = model.fit(final_training_features, final_training_labels, \n",
    "                     validation_data=(final_validation_features, final_validation_labels), epochs=20, batch_size=200)\n",
    "\n",
    "best_loss = modelfit.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0044)\n",
      "0.0035880310460925102\n"
     ]
    }
   ],
   "source": [
    "print(eff_ROLO)\n",
    "print(best_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improvement percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.4758)\n"
     ]
    }
   ],
   "source": [
    "print((eff_ROLO - best_loss)*100/eff_ROLO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
